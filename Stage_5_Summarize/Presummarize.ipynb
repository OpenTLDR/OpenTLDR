{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "tags": []
            },
            "source": [
                "# Summarize Content Nodes WITHOUT focus\n",
                "Uses LLM summerization on the content text only and saves it as metadata for the content node.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import logging\n",
                "import re\n",
                "import json\n",
                "import dotenv\n",
                "\n",
                "dotenv.load_dotenv()  # Load environment variables from .env file"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Parameters\n",
                "OpenTLDR workflows use the notebook block tagged as \"parameters\" to inject variables (for example to change the LLM model).\n",
                "\n",
                "> **Do Not Change Variable Names in the Parameters Block** you are welcome to change the values of these parameter variables, but please do not change their names. They are used elsewhere in the notebook and in other workflow processes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "parameters"
                ]
            },
            "outputs": [],
            "source": [
                "#Parameters\n",
                "\n",
                "# If you set the llm_config to None, it will use the environment variable LLM_CONFIG\n",
                "# Otherwise, here are some options (to run an LLM locally, you will need to download the model to your local machine)\n",
                "# llm_config = {'type': 'GPT4ALL', 'device':'gpu', 'model':'../LLM_Models/mistral-7b-openorca.gguf2.Q4_0.gguf'}\n",
                "# llm_config = {'type': 'Ollama', 'model':'mistral:latest'}\n",
                "# llm_config = {'type': 'ChatGPT', 'model':'gpt-4'}\n",
                "llm_config = None\n",
                "\n",
                "llm_prompt = '''\n",
                "    Write a concise summary of this content:\\n {content}\n",
                "    '''\n",
                "#for ChatGPT, you need to set the environment variable CHATGPT_API_KEY\n",
                "chatgpt_api_key = os.getenv(\"CHATGPT_API_KEY\")\n",
                "\n",
                "# Logging level ranges are (from least to most verbose): ERROR, WARN, INFO, DEBUG\n",
                "logging_level = logging.INFO\n",
                "\n",
                "# List of the UniqueIds to Ingest\n",
                "list_of_uids = None\n",
                "\n",
                "# level of unnecessary output\n",
                "verbose = True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "logging.getLogger(\"OpenTLDR\").setLevel(logging_level)\n",
                "\n",
                "import opentldr.Domain as domain\n",
                "from opentldr import KnowledgeGraph\n",
                "\n",
                "kg=KnowledgeGraph()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Load Content Nodes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if list_of_uids is None:\n",
                "    list_of_uids = kg.get_all_node_uids_by_tag(\"Content\")\n",
                "\n",
                "if verbose:\n",
                "    print (\"Found {} Content nodes to attempt pre-summarization (i.e., untailored).\".format(len(list_of_uids)))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Run an LLM Model\n",
                "This notebook uses the `Summarizer` class to run an LLM model. \n",
                "You can set the LLM model by changing the `llm_config` variable in the parameters block above or setting LLM_CONFIG in the .env file or environment variable."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import Summarizer\n",
                "llm:Summarizer = Summarizer.getSummarizer(llm_config, logging_level=logging_level)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Build the prompt and run the LLM\n",
                "This includes the original content, the request it is tailored for, and the explaination of the shortest path through the knowledge graph used to connect them."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "for content_uid in list_of_uids:  \n",
                "    content = kg.get_content_by_uid(content_uid)\n",
                "    original= content.text\n",
                "    #print(\"\\tOriginal Content:\\t{text}\".format(text=original))\n",
                "    #print(\"\\tPath Text:\\t{text}\".format(text=path_text))\n",
                "    \n",
                "    if content.metadata is not None:\n",
                "        if \"summary\" in content.metadata.keys():\n",
                "            if len(content.metadata[\"summary\"]) > 60:\n",
                "                print (\"... already summarized...\")\n",
                "                continue\n",
                "            else:\n",
                "                # assume there was something wrong with it, strip everything out and try again\n",
                "                original = re.sub('[^a-zA-Z0-9 \\n]', '', original)\n",
                "    else:\n",
                "        content.metadata = dict()\n",
                "\n",
                "    if len(original) < 10:\n",
                "        print(\"Deleting: {}\".format(content.to_text()))\n",
                "        kg.delete_content(content)\n",
                "        continue\n",
                "\n",
                "    print(\"Summarizing... {t}\\t{s}\".format(t=content.title, s=len(content.text)))\n",
                "\n",
                "    prompt_text = llm_prompt.format(content=original).strip()\n",
                "    summary= llm.summarize(prompt_text)\n",
                "\n",
                "    print(\"summary ({reduction}):\\t{text}\".format(reduction=round(len(summary)/len(original),3),text=summary))\n",
                "    \n",
                "    # if it fails try it again without extra characters that might creep into content during collection\n",
                "    if len(summary) < 10:\n",
                "        logging.warning(\"Summarization failed for this content, trying without extra characters.\")\n",
                "        summary =  llm.summarize(re.sub('[^a-zA-Z0-9 \\n]', '', prompt_text))\n",
                "    \n",
                "    if len(summary) < 10:\n",
                "        logging.error(\"Pre-Summarization too short.\")\n",
                "    \n",
                "    content.metadata[\"summary\"] = summary\n",
                "    content.save()\n",
                "    \n",
                "    print(\"\\n\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "kg.close()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "opentldr-env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}