{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "22652f6a-3d56-4a25-9c2c-7d149882e084",
            "metadata": {},
            "source": [
                "# Load Content (Active Data)\n",
                "\n",
                "> **Active Data** represents the stream on information content coming into system, typically on a daily basis. For example, a series of news articles published each day and what things are mentioned in those articles are all Active Data. \n",
                " \n",
                "This notebook reads Content from a DataRepo and ingests them as nodes into your KnowledgeGraph.\n",
                "\n",
                "* Iterate through the content in the repository\n",
                "\n",
                "* For each Content:\n",
                "- Create (or merge) a Content node\n",
                "- Link the Content node to the Source node (create if necessary)\n",
                "- Load known Keywords (in Ref Data) and create Entities for any that exist in the Request Node\n",
                "- Run Named Entity Recognition on the Request Node text and create Entities for any found\n",
                "\n",
                "The result of this step includes adding:\n",
                "- User nodes (existing or newly created)\n",
                "- Content nodes, connected to Source nodes with an IS_FROM relationship\n",
                "- Entity nodes, connected to Content node by a MENTIONED_IN relationship\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "615ea347",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import logging\n",
                "import re"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e1f7ea30",
            "metadata": {},
            "source": [
                "## Parameters can be passed into the Notebook from an OpenTLDR Workflow\n",
                "OpenTLDR workflows use the notebook block tagged as \"parameters\" to inject variables (for example to redirect the source of content).\n",
                "\n",
                "> **Changing Variable Names in the Parameters Block** you are welcome to change the values of these parameter variables, but if you change their names, be aware they are used elsewhere in the notebook and in other workflow stages."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a7a37381",
            "metadata": {
                "tags": [
                    "parameters"
                ]
            },
            "outputs": [],
            "source": [
                "# Notebook Specific Parameters\n",
                "\n",
                "data_repo_config = {'repo_type': 'files','path': '../Data/Sample/content'}\n",
                "spacy_model = \"en_core_web_sm\"\n",
                "\n",
                "# Logging level ranges are (from least to most verbose): ERROR, WARN, INFO, DEBUG\n",
                "logging_level = logging.INFO\n",
                "\n",
                "# List of the UserIdqs to Ingest\n",
                "list_of_uids = None\n",
                "\n",
                "# level of unnecessary output\n",
                "verbose = True"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "b5975501-f3e1-46e9-a870-affc262e1085",
            "metadata": {},
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "173be13b-5f0b-45e1-8438-571e3f09b28a",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "logging.getLogger(\"OpenTLDR\").setLevel(logging_level)\n",
                "\n",
                "from opentldr.Domain import Source, Content, Entity\n",
                "from opentldr import KnowledgeGraph, DataRepo\n",
                "\n",
                "kg=KnowledgeGraph()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "555d5d08-bfc2-46d5-a928-857c1e68f49f",
            "metadata": {},
            "source": [
                "## Ingest Content nodes from data repo into the KG"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cb4dd536",
            "metadata": {},
            "outputs": [],
            "source": [
                "if data_repo_config is not None:\n",
                "\n",
                "    repo = DataRepo(kg,data_repo_config)\n",
                "    \n",
                "    if verbose:\n",
                "        print(\"Loading Content from: {}\".format(repo.describe()))\n",
                "\n",
                "    list_of_uids =  repo.importData()\n",
                "    print(\"Loaded {count} articles from the repository.\".format(count=len(list_of_uids)))\n",
                "\n",
                "else:\n",
                "    print(\"No DataRepo specified for Content.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cf50230d",
            "metadata": {},
            "source": [
                "## Process the newly created Content nodes\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "835c9a9d",
            "metadata": {},
            "source": [
                "### Named Entity Recognition (NER)\n",
                "\n",
                "This is the process of detecting objects that are identified within the text."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bcf84a52",
            "metadata": {},
            "outputs": [],
            "source": [
                "from NerWithSpacy import NerWithSpacy\n",
                "ner = NerWithSpacy(verbose=True, model_name=spacy_model)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "de38bc4e",
            "metadata": {},
            "source": [
                "### Keywords\n",
                "One example of such an entity are the presense of keywords."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b7354d20",
            "metadata": {},
            "outputs": [],
            "source": [
                "keywords = []\n",
                "\n",
                "for node in kg.get_all_reference_nodes():\n",
                "    if node.type == \"KEYWORD\":\n",
                "        keywords.append(node.text)\n",
                "if verbose:\n",
                "    print(\"Will look for {} known keywords: {}\".format(len(keywords),keywords))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dd14c78c",
            "metadata": {},
            "source": [
                "### Discover Entities in the Content node's text\n",
                "Iterate over the imported Requests, recognize entities of interest, and add those nodes to the KG\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e584fd14",
            "metadata": {},
            "outputs": [],
            "source": [
                "for uid in list_of_uids:\n",
                "    node = kg.get_content_by_uid(uid)\n",
                "    if verbose:\n",
                "        print(\"\\nProcessing Content {title}:\".format(title=node.title))\n",
                "    \n",
                "    # avoid adding duplicate entities for the same text value\n",
                "    ner.skip = [ e.text for e in kg.get_entities_by_content(node) ]\n",
                "\n",
                "   # Iterate Keywords first\n",
                "    for keyword in keywords:\n",
                "        if keyword not in ner.skip:\n",
                "            if re.search(keyword, node.text, re.IGNORECASE):\n",
                "                entity_node=kg.add_entity(node,text=keyword, type=\"KEYWORD\")\n",
                "                ner.skip.append(entity_node.text)\n",
                "                if verbose:\n",
                "                    print(\" - Added entity '{text}' of type {type}\".format(text=entity_node.text, type=entity_node.type))\n",
                "    \n",
                "\n",
                "    # Then search for Named Entities (avoid text being both)\n",
                "    for type, text in ner.process(node.text):\n",
                "        kg.add_entity(node = node, text=text, type=type)\n",
                "        ner.skip.append(text)\n",
                "        if verbose:\n",
                "            print(\" - Added entity '{text}' of type {type}\".format(text=text, type=type))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "ba279766-e272-4ce1-a4df-43efb77fb86d",
            "metadata": {
                "tags": []
            },
            "source": [
                "# Close the KG"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "75e11866-eb61-4bc3-894a-55f8105d59f1",
            "metadata": {},
            "outputs": [],
            "source": [
                "kg.close()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "opentldr-env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}