{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# US Dept of State - Collector for OpenTLDR (Update)\n",
                "This notebook pulls raw data from the internet and formats it for OpenTLDR ingest as a .json file.\n",
                "The output json file can be shared with multiple OpenTLDR instances as a file system or S3 bucket.\n",
                "\n",
                "In this Collector folder are:\n",
                "- setup_collector.sh - used to create the python virtual environment intended for this collector. This will include pip installing the modules in the requirements.txt file.\n",
                "- execute.sh - this script can be called from a cronjob in order to automate the collection process.\n",
                "- .env - this file should be modified for the environment you are running the collector in."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import logging\n",
                "import re\n",
                "\n",
                "from dotenv import load_dotenv\n",
                "load_dotenv()\n",
                "\n",
                "from RssFeed import RssFeed\n",
                "from RepoWriter import RepoWriter"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "parameters"
                ]
            },
            "outputs": [],
            "source": [
                "# Parameters\n",
                "\n",
                "# The path where this agent should write the .json files for content\n",
                "live_data_repo_path = os.getenv('LIVE_DATA_REPO_PATH')\n",
                "\n",
                "# The path where this agent should write full source files temporarily\n",
                "download_media = False # State already provides full text in RSS (and it is cleaner)\n",
                "media_cache_path = os.getenv('MEDIA_CACHE_PATH')\n",
                "\n",
                "# Name of Source to use in OpenTLDR objects\n",
                "rss_source = \"state\"\n",
                "organize_by_source = True\n",
                "\n",
                "# URLs for the feeds to scrape for this Source\n",
                "rss_feed_urls = [\n",
                "    \"https://www.state.gov/rss-feed/press-releases/feed/\",\n",
                "    \"https://www.state.gov/rss-feed/secretarys-remarks/feed/\",\n",
                "    \"https://www.state.gov/rss-feed/africa/feed/\",\n",
                "    \"https://www.state.gov/rss-feed/arms-control-and-international-security/feed/\",\n",
                "    \"https://www.state.gov/rss-feed/climate-environment-and-conservation/feed/\",\n",
                "    \"https://www.state.gov/rss-feed/collected-department-releases/feed/\",\n",
                "    \"https://www.state.gov/rss-feed/counterterrorism/feed/\",\n",
                "    \"https://www.state.gov/rss-feed/democracy-human-rights-and-labor/feed/\",\n",
                "    \"https://www.state.gov/rss-feed/department-press-briefings/feed/\",\n",
                "    \"https://www.state.gov/rss-feed/diplomatic-security/feed/\",\n",
                "    \"https://www.state.gov/rss-feed/direct-line-to-american-business/feed/\",\n",
                "    \"https://www.state.gov/rss-feed/east-asia-and-the-pacific/feed/\",\n",
                "    \"https://www.state.gov/rss-feed/economic-energy-agricultural-and-trade-issues/feed/\",\n",
                "    \"https://www.state.gov/rss-feed/europe-and-eurasia/feed/\",\n",
                "    \"https://www.state.gov/rss-feed/international-expositions/feed/\",\n",
                "    \"https://www.state.gov/rss-feed/international-health-issues/feed/\",\n",
                "    \"https://www.state.gov/rss-feed/international-organizations/feed/\",\n",
                "    \"https://www.state.gov/rss-feed/law-enforcement-narcotics-anti-corruption/feed/\",\n",
                "    \"https://www.state.gov/rss-feed/near-east/feed/\",\n",
                "    \"https://www.state.gov/rss-feed/population-refugees-and-migration/feed/\",\n",
                "    \"https://www.state.gov/rss-feed/public-schedule/feed/\",\n",
                "    \"https://www.state.gov/rss-feed/south-and-central-asia/feed/\",\n",
                "    \"https://www.state.gov/rss-feed/trafficking-in-persons/feed/\",\n",
                "    \"https://www.state.gov/rss-feed/treaties-new/feed/\",\n",
                "    \"https://www.state.gov/rss-feed/western-hemisphere/feed/\",\n",
                "    \"https://www.state.gov/rss-feed/womens-issues/feed/\",\n",
                "]\n",
                "\n",
                "# Some sites verify recent user_agent configurations\n",
                "user_agent = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36\"\n",
                "\n",
                "# This RSS Feed keeps a fair amount of historic data that we want to filter out.\n",
                "date:str = None\n",
                "days_history = 9999    # it seems like forever...\n",
                "\n",
                "# Logging level ranges are (from least to most verbose): ERROR, WARN, INFO, DEBUG\n",
                "logging_level = logging.INFO\n",
                "\n",
                "# level of unnecessary output\n",
                "verbose = True"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Process Parameters\n",
                "Parameters are passed in as strings that sometimes need to be converted to other object format.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set the Data Filtering\n",
                "\n",
                "from datetime import datetime, timedelta\n",
                "import pytz\n",
                "\n",
                "# Default to today\n",
                "today = datetime.now()\n",
                "if date is not None: \n",
                "    today = datetime.strptime(date,\"%Y-%m-%d\")\n",
                "\n",
                "# defaults to previous 1 day\n",
                "last_read = today - timedelta(days=days_history)\n",
                "\n",
                "print(\"Today is {}, will atttempt to download content since {}.\".format(today.strftime('%Y-%m-%d'),last_read.strftime('%Y-%m-%d')))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify where the .json files should be stored.\n",
                "if live_data_repo_path is None:\n",
                "    live_data_repo_path = os.path.join(\"..\",\"Data\",\"Live\")\n",
                "\n",
                "if organize_by_source:\n",
                "    live_data_repo_path= os.path.join(live_data_repo_path,rss_source)\n",
                "\n",
                "print (\"Writing Content to: {}\".format(live_data_repo_path))\n",
                "\n",
                "# Verify where the media files should be stored.\n",
                "if media_cache_path is None and download_media:\n",
                "    media_cache_path = os.path.join('..','Data','MediaCache')\n",
                "\n",
                "if download_media:\n",
                "    print (\"Cacheing Media files to: {}\".format(media_cache_path))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ensure that these paths exist and create them if they do not\n",
                "\n",
                "if not os.path.exists(live_data_repo_path):\n",
                "    print (\"Creating directory: {}\".format(live_data_repo_path))\n",
                "    os.makedirs(live_data_repo_path)\n",
                "\n",
                "if download_media and not os.path.exists(media_cache_path):\n",
                "    print (\"Creating directory: {}\".format(media_cache_path))\n",
                "    os.makedirs(media_cache_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Process State RSS Feed\n",
                "This collector pulls entries from the RSS Feed and structures them for OpenTLDR Ingest."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "reader=RssFeed(rss_source, user_agent=user_agent)\n",
                "reader.set_filter(today=today, earliest=last_read)\n",
                "reader.set_log_level(logging_level)\n",
                "#reader.archive = os.path.join(live_data_repo_path,\"rss_archive\",datetime.now().strftime(\"%Y-%m-%d\"))\n",
                "\n",
                "writer=RepoWriter(live_data_repo_path)\n",
                "writer.set_log_level(logging_level)\n",
                "\n",
                "# DeptOfState uses full html as their description, so it includes some htmls markups\n",
                "htmlish_tags= re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
                "\n",
                "for feed in rss_feed_urls:\n",
                "    try:\n",
                "        for entry in reader.fetch_feed(feed, type = \"press release\"):\n",
                "\n",
                "            # Clean up source-specific issues\n",
                "            entry['text'] = re.sub(htmlish_tags,' ', entry['text'])\n",
                "            entry['author'] = \"US Dept of State\"\n",
                "            source_html_url = entry['url']\n",
                "\n",
                "            # Write out a content node \n",
                "            repo_uid = writer.write_content(entry)\n",
                "    \n",
                "            if repo_uid is not None and download_media:\n",
                "                try:\n",
                "                    for m in entry['metadata']['media']:\n",
                "                        media_url:str = m\n",
                "                        media_filename:str = writer.url_to_filename(m)\n",
                "                        media_full_path = os.path.join(media_cache_path,media_filename)\n",
                "\n",
                "                        if not os.path.exists(media_full_path):                \n",
                "                            print (\"Downloading media file {} for {}\".format(media_full_path,repo_uid))\n",
                "                            writer.http_copy(media_url, media_full_path)\n",
                "                        else:\n",
                "                            print (\"Already have media file {} for {}\".format(media_full_path,repo_uid))\n",
                "\n",
                "                    # Dept of State puts a clean version of their entire text content in the rss feed.\n",
                "                    # They are also pretty strict about blocking requests, so best to just not download media unless you need to.\n",
                "\n",
                "                except:\n",
                "                    print (\"Failed to download media file for {}.\".format(hash))\n",
                "    \n",
                "    except Exception as e:\n",
                "        print (\"RSS Feed {} had error: {}\".format(feed, e))     "
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "opentldr-env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}