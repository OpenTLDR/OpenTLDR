{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ISW Collector for OpenTLDR (Update)\n",
                "This notebook pulls raw data from the internet and formats it for OpenTLDR ingest as a .json file.\n",
                "The output json file can be shared with multiple OpenTLDR instances as a file system or S3 bucket."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "import os\n",
                "import logging\n",
                "import re\n",
                "\n",
                "from dotenv import load_dotenv\n",
                "load_dotenv()\n",
                "\n",
                "from RssFeed import RssFeed\n",
                "from RepoWriter import RepoWriter\n",
                "from HtmlScrape import fetch_html, extract_text_from_element, url_to_filename"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "parameters"
                ]
            },
            "outputs": [],
            "source": [
                "# Parameters\n",
                "\n",
                "# The path where this agent should write the .json files for content\n",
                "live_data_repo_path = os.getenv('LIVE_DATA_REPO_PATH')\n",
                "\n",
                "# The path where this agent should write full source files temporarily\n",
                "download_media = False\n",
                "media_cache_path = os.getenv('MEDIA_CACHE_PATH')\n",
                "\n",
                "# Name of Source to use in OpenTLDR objects\n",
                "rss_source = \"isw\"\n",
                "organize_by_source = True\n",
                "\n",
                "# URLs for the feeds to scrape for this Source\n",
                "rss_feed_urls = [\n",
                "    \"https://www.understandingwar.org/feed-afghanistan.xml\",\n",
                "    \"https://www.understandingwar.org/feeds-iraq.xml\",\n",
                "]\n",
                "\n",
                "# Filters - excludes some content\n",
                "date:str = None\n",
                "days_history = 4000 # Some older ISW entries have errors in the formatting...\n",
                "\n",
                "# Some sites verify recent user_agent configurations\n",
                "user_agent = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36\"\n",
                "\n",
                "# Logging level ranges are (from least to most verbose): ERROR, WARN, INFO, DEBUG\n",
                "logging_level = logging.INFO\n",
                "\n",
                "# level of unnecessary output\n",
                "verbose = True"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Process Parameters\n",
                "Parameters are passed in as strings that sometimes need to be converted to other object format.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set the Data Filtering\n",
                "from datetime import datetime, timedelta\n",
                "import pytz\n",
                "\n",
                "# Default to today\n",
                "today = datetime.now()\n",
                "if date is not None: \n",
                "    today = datetime.strptime(date,\"%Y-%m-%d\")\n",
                "\n",
                "# defaults to previous 1 day\n",
                "last_read = today - timedelta(days=days_history)\n",
                "\n",
                "print(\"Today is {}, will atttempt to download content since {}.\".format(today.strftime('%Y-%m-%d'),last_read.strftime('%Y-%m-%d')))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify where the .json files should be stored.\n",
                "if live_data_repo_path is None:\n",
                "    live_data_repo_path = os.path.join(\"..\",\"Data\",\"Live\")\n",
                "\n",
                "if organize_by_source:\n",
                "    live_data_repo_path= os.path.join(live_data_repo_path,rss_source)\n",
                "\n",
                "print (\"Writing Content to: {}\".format(live_data_repo_path))\n",
                "\n",
                "# Verify where the media files should be stored.\n",
                "if media_cache_path is None and download_media:\n",
                "    media_cache_path = os.path.join('..','Data','MediaCache')\n",
                "\n",
                "if download_media:\n",
                "    print (\"Cacheing Media files to: {}\".format(media_cache_path))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ensure that these paths exist and create them if they do not\n",
                "\n",
                "if not os.path.exists(live_data_repo_path):\n",
                "    print (\"Creating directory: {}\".format(live_data_repo_path))\n",
                "    os.makedirs(live_data_repo_path)\n",
                "\n",
                "if download_media and not os.path.exists(media_cache_path):\n",
                "    print (\"Creating directory: {}\".format(media_cache_path))\n",
                "    os.makedirs(media_cache_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Process ISW RSS Feed\n",
                "This collector pulls entries from the RSS Feed and structures them for OpenTLDR Ingest."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "reader=RssFeed(rss_source, user_agent=user_agent)\n",
                "reader.set_filter(today=today, earliest=last_read)\n",
                "reader.set_log_level(logging_level)\n",
                "#reader.archive = os.path.join(live_data_repo_path,\"rss_archive\",datetime.now().strftime(\"%Y-%m-%d\"))\n",
                "\n",
                "writer=RepoWriter(live_data_repo_path)\n",
                "writer.set_log_level(logging_level)\n",
                "\n",
                "# ISW uses full html as their description, so it includes some htmls markups\n",
                "htmlish_tags= re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
                "\n",
                "# For Debugging\n",
                "reader.set_log_level(logging.INFO)\n",
                "writer.set_log_level(logging.INFO)\n",
                "\n",
                "for feed in rss_feed_urls:\n",
                "    try:\n",
                "        for entry in reader.fetch_feed(feed, type = \"reports\"):\n",
                "\n",
                "            # Clean up source-specific issues\n",
                "            entry['text'] = re.sub(htmlish_tags,' ', entry['text'])\n",
                "            source_html_url = entry['url']\n",
                "\n",
                "            # Write out a content node \n",
                "            repo_uid = writer.write_content(entry)\n",
                "\n",
                "            # Download Full Media into raw folder\n",
                "            if repo_uid is not None and download_media:\n",
                "                try:\n",
                "\n",
                "                    html_media_path = os.path.join(media_cache_path,\"{}.html\".format(repo_uid))\n",
                "                    writer.http_copy(source_html_url, html_media_path)\n",
                "\n",
                "                except Exception as e:\n",
                "                    print (\"Failed to download html file for {}: {}\".format(repo_uid,e))    \n",
                "\n",
                "                try:\n",
                "                    for m in entry['metadata']['media']:\n",
                "                        media_url:str = m\n",
                "                        media_filename:str = writer.url_to_filename(m)\n",
                "                        media_full_path = os.path.join(media_cache_path,media_filename)\n",
                "\n",
                "                        if not os.path.exists(media_full_path):                \n",
                "                            print (\"Downloading media file {} for {}\".format(media_full_path,repo_uid))\n",
                "                            writer.http_copy(media_url, media_full_path)\n",
                "                        else:\n",
                "                            print (\"Already have media file {} for {}\".format(media_full_path,repo_uid))\n",
                "\n",
                "                except Exception as e:\n",
                "                    print (\"Failed to download media file for {}: {}\".format(repo_uid,e))\n",
                "    \n",
                "    except Exception as e:\n",
                "        print (\"RSS Feed {} had error: {}\".format(feed, e))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "opentldr-env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}