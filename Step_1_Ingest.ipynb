{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "22652f6a-3d56-4a25-9c2c-7d149882e084",
            "metadata": {},
            "source": [
                "# Step 1: Ingest Active Data\n",
                "> **Active Data** represents the stream on information content coming into system, typically on a daily basis. For example, a series of news articles published each day and what things are mentioned in those articles are all Active Data. \n",
                " \n",
                "![step1](resources/Step1_Ingest.png)\n",
                "\n",
                "This notebook reads news articles (Content) and ingests them as nodes into your Knowledge Graph.\n",
                "* Import OpenTLDR Knowledge Graph - which automatically uses your .env to connect to Neo4J.\n",
                "* Iterate through the content text in the repository\n",
                "* For each article:\n",
                "- Create (or merge) a Content node that represents where the article was published.\n",
                "- Run NLP for \"Named Entity Recognition\" to identify the entities mentioned.\n",
                "\n",
                "The result of this step includes:\n",
                "- Source nodes\n",
                "- Content nodes, connected to Source nodes with an IS_FROM relationship\n",
                "- Entity nodes, connected to Content nodes with a MENTIONED_IN relationship"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "b5975501-f3e1-46e9-a870-affc262e1085",
            "metadata": {},
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "aaf24eb0",
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\n",
                "\n",
                "#logging.getLogger(\"OpenTLDR\").setLevel(logging.ERROR)  # Less output\n",
                "#logging.getLogger(\"OpenTLDR\").setLevel(logging.WARN)   # Default\n",
                "logging.getLogger(\"OpenTLDR\").setLevel(logging.INFO)   # More output\n",
                "#logging.getLogger(\"OpenTLDR\").setLevel(logging.DEBUG)  # So much output"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "173be13b-5f0b-45e1-8438-571e3f09b28a",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "import os\n",
                "from datetime import datetime\n",
                "\n",
                "from opentldr.Domain import Source, Content, Entity\n",
                "from opentldr import DataRepo\n",
                "from opentldr import KnowledgeGraph\n",
                "\n",
                "kg=KnowledgeGraph()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e1f7ea30",
            "metadata": {},
            "source": [
                "## Parameters\n",
                "OpenTLDR workflows use the notebook block tagged as \"parameters\" to inject variables (for example to redirect the source of content).\n",
                "\n",
                "> **Do Not Change Variable Names in the Parameters Block** you are welcome to change the values of these parameter variables, but please do not change their names. They are used elsewhere in the notebook and in other workflow processes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a7a37381",
            "metadata": {
                "tags": [
                    "parameters"
                ]
            },
            "outputs": [],
            "source": [
                "#Parameters\n",
                "\n",
                "active_date_repo_config = {'repo_type': 'files','path': './sample_data/content'}\n",
                "\n",
                "spacy_model=\"en_core_web_sm\"\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "555d5d08-bfc2-46d5-a928-857c1e68f49f",
            "metadata": {},
            "source": [
                "## Ingest text files from the sources directory into the KG"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cb4dd536",
            "metadata": {},
            "outputs": [],
            "source": [
                "# if you plan to only run this notebook multiple times you could clean out the content nodes each time\n",
                "# kg.delete_all_content()\n",
                "\n",
                "if active_date_repo_config is not None:\n",
                "    repo = DataRepo(kg,active_date_repo_config)\n",
                "    list_of_uids =  repo.importData()\n",
                "    print(\"Loaded {count} articles from the repository.\".format(count=len(list_of_uids)))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "835c9a9d",
            "metadata": {},
            "source": [
                "## Named Entity Recognition (NER)\n",
                "This is the process of detecting objects that are identified within the text and associating them with one of the above types."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "3794c35a-bad4-4074-9972-dd46396b01a8",
            "metadata": {
                "tags": [
                    "parameters"
                ]
            },
            "source": [
                "### Setup spaCy for NLP/NER"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c8f06713-f1d8-444f-badd-eda5bd2b7939",
            "metadata": {
                "scrolled": true,
                "tags": []
            },
            "outputs": [],
            "source": [
                "import spacy\n",
                "import sys\n",
                "import subprocess\n",
                "\n",
                "# if you have a GPU and your imstalled the spacy[cuda] package, it will use the GPU\n",
                "spacy.prefer_gpu()\n",
                "\n",
                "# SpaCy uses a language model that needs to be downloaded, this checks if that has been done\n",
                "# and if it has not, it will download the model (and some dependencies) which can take a bit.\n",
                "if not spacy.util.is_package(spacy_model):\n",
                "        print(\"Downloading spaCy NLP Model...\")\n",
                "        #equivelent to running -> !{sys.executable} -m spacy download {spacy_model}\n",
                "        subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", spacy_model])\n",
                "else:\n",
                "        print(\"spaCy model ({model}) is already downloaded.\".format(model=spacy_model))\n",
                "\n",
                "nlp = spacy.load(spacy_model)   \n",
                "\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "fe8e1eb0-974f-4d4f-bda5-8f9c0058e40b",
            "metadata": {
                "tags": []
            },
            "source": [
                "### List NER entity \"types\" that Spacy will look for"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7ec2e8ed",
            "metadata": {},
            "outputs": [],
            "source": [
                "for label in nlp.get_pipe('ner').labels:\n",
                "    print(label, '\\t\\t', spacy.explain(label))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7d5fc58f",
            "metadata": {},
            "source": [
                "### Function for running NER on a text string\n",
                "The call to \"spacy.display.render\" prints out the text with annotations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e6c0af56",
            "metadata": {},
            "outputs": [],
            "source": [
                "def named_entity_recognition(text:str):\n",
                "        doc = nlp(text)\n",
                "        spacy.displacy.render(doc, style='ent')\n",
                "        return doc.ents"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dd14c78c",
            "metadata": {},
            "source": [
                "### Iterate over the content, recognize entities of interest, and add those nodes to the KG\n",
                "If you are only running this workflow directly, this may re-process existing nodes inefficiently.\n",
                "However, it is possible that content is added without running the this notebook, so we need to process those entries.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e584fd14",
            "metadata": {},
            "outputs": [],
            "source": [
                "for content_node in kg.get_all_content():\n",
                "    print(\"\\nProcessing {title}:\".format(title=content_node.title))\n",
                "    \n",
                "    # avoid adding duplicate entities for the same text value\n",
                "    existing_entities=kg.get_entities_by_content(content_node)\n",
                "    unique=[ e.text for e in existing_entities ]\n",
                "    \n",
                "    for entity in named_entity_recognition(content_node.text):\n",
                "        if entity.label_ not in ['DATE','TIME','MONEY', 'CARDINAL', 'ORDINAL','PERCENT','QUANTITY','WORK_OF_ART']:\n",
                "            if entity.text not in unique:\n",
                "                entity_node=kg.add_entity(content_node,text=entity.text, type=entity.label_)\n",
                "                print(\" - Added entity '{text}' of type {type}\".format(text=entity_node.text, type=entity_node.type))\n",
                "                unique.append(entity_node.text)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cf3fb5fe",
            "metadata": {},
            "source": [
                "## Verify which entities were discovered\n",
                "At this point in the notebooks, the KG should contain a set of Entities that have been discovered.\n",
                "Each entity should be linked to the Content (e.i., the news article) that it was mentioned in."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7412963a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Makes a cypher query to the KG\n",
                "all_entities = kg.get_all_entities();\n",
                "\n",
                "print(\"Found {count} entity nodes in the knowledge graph:\".format(count=len(all_entities)))\n",
                "\n",
                "# Iterate thru the Entity Nodes and print info for each\n",
                "for entity in all_entities:\n",
                "    citable_node=entity.get_mentioned_in()\n",
                "    \n",
                "    if hasattr(citable_node,\"url\"): # a request wouldn't have a url...\n",
                "        print(\" - {type}({uid}):\\t'{text}' was mentioned in {url}\".format(\n",
                "            type=entity.type, uid=entity.uid, text=entity.text, url=citable_node.url))\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "ba279766-e272-4ce1-a4df-43efb77fb86d",
            "metadata": {
                "tags": []
            },
            "source": [
                "# Close down any remote connections"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "75e11866-eb61-4bc3-894a-55f8105d59f1",
            "metadata": {},
            "outputs": [],
            "source": [
                "kg.close()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "opentldr-env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}