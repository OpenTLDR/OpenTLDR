{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from datetime import date\n",
                "\n",
                "from opentldr import Workflow"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Specify the Workflow in code\n",
                "The workflow includes:\n",
                "- **ONE TIME**: This block wipes the KG and resets it (only run if parameter \"initialize\" is set to True).\n",
                "- **Daily**: this block simulates the daily live run."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Parameters\n",
                "- initialize (boolean) - determines if the KG gets wiped at start (true) or not (false).\n",
                "- today (string) - whatever date represents today formatted as \"YYYY-MM-DD\".\n",
                "- historic_days_to_run (list of date strings) - will run each day in order given.\n",
                "- use_local_files (boolean) - sets the data repo to either local (true) or S3 (false).\n",
                "- data_directory (path as string) - if using a local directory, which directory should be used.\n",
                "\n",
                "Note: regardless of where the content is pulled from, the reference data .csv files need to be in the directory specified by the data_directory parameter."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "parameters"
                ]
            },
            "outputs": [],
            "source": [
                "# Parameters\n",
                "initialize = False\n",
                "\n",
                "today = str(date.today())\n",
                "days_to_run = []\n",
                "\n",
                "# The main directory for loading data for this notebook\n",
                "use_local_files = True\n",
                "data_directory = \"../Data/TechInt\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup a list of dates for which to run TLDRs\n",
                "\n",
                "if today not in days_to_run:\n",
                "    days_to_run.append(today)\n",
                "print (\"Running: \",days_to_run)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_data_repo_config(folder:str, today:str=None):\n",
                "    '''\n",
                "    format the data_repo_config json based on above and given subfolder\n",
                "    '''\n",
                "    \n",
                "    path = format(os.path.join(data_directory,folder))\n",
                "\n",
                "    if today is not None:\n",
                "        path = format(os.path.join(data_directory,today,folder))\n",
                "\n",
                "    if use_local_files:\n",
                "        return {\n",
                "            'repo_type': 'files',\n",
                "            'path': path\n",
                "        }\n",
                "    else:\n",
                "        return {\n",
                "            'repo_type': 's3',\n",
                "            'bucket': os.getenv(\"S3_BUCKET\"),\n",
                "            'aws_access_key_id': os.getenv(\"S3_ACCESS_KEY_ID\"),\n",
                "            'aws_secret_access_key': os.getenv(\"S3_SECRET_KEY\"),\n",
                "            'prefix': path\n",
                "        }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### One-Time Initialization\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if initialize:\n",
                "\n",
                "    # Initialize the KnowledgeGraph\n",
                "    workflow = {\n",
                "        \"Output\": \"./READ_ONLY_OUTPUT_TECHINT/SETUP\",\n",
                "\n",
                "        \"Notebooks\": [\n",
                "            # Erases the entire KG - so only do this when you intend to\n",
                "            [\"Stage_1_Initialize/Clear_All.ipynb\",{}],\n",
                "\n",
                "            # Load up a Reference Data KG that is relevent to the Arxiv dataset\n",
                "            [\"Stage_1_Initialize/Load_CSV_Reference_Data.ipynb\",{\n",
                "                \"keyword_to_concept_csv_file\": os.path.join(data_directory,\"reference\",\"keywords.csv\"),\n",
                "                \"concept_to_concept_csv_file\": os.path.join(data_directory,\"reference\",\"concepts.csv\"),\n",
                "            }],\n",
                "\n",
                "            # Load up the set of example Requests from this location\n",
                "            [\"Stage_2_Ingest/Load_Requests.ipynb\",{\n",
                "                \"data_repo_config\": get_data_repo_config('request'),\n",
                "            }],\n",
                "        ]}\n",
                "\n",
                "    print (\"Initializing the KG now...\")\n",
                "    wf = Workflow(workflow)\n",
                "    wf.run()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Daily"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for today in days_to_run:\n",
                "    print(\"Running for {}\".format(today))\n",
                "\n",
                "    workflow = {\n",
                "        \n",
                "        # Where a read-only version of the notebook AFTER execution is stored\n",
                "        \"Output\": \"../READ_ONLY_OUTPUT_TECHINT/{}\".format(today),\n",
                "        \n",
                "        # Parameters passed into all notebooks in workflow\n",
                "        \"Common\": {\n",
                "            \"logging_level\":10,\n",
                "            \"vebose\": True,\n",
                "        },\n",
                "\n",
                "        # Order and parameters of notebooks to execute in workflow\n",
                "        \"Notebooks\": [\n",
                "\n",
                "            # Setup the KG\n",
                "            [ \"../Stage_1_Initialize/Clear_Live_Content.ipynb\", {}],\n",
                "\n",
                "            # Load Content and Requests\n",
                "            [ \"../Stage_2_Ingest/Load_Content.ipynb\", {\n",
                "                \"data_repo_config\": {'repo_type': 'files', 'path': '../Data/Samplecontent'},\n",
                "            }],\n",
                "\n",
                "            [ \"../Stage_2_Ingest/Load_Requests.ipynb\", {\n",
                "                \"data_repo_config\": {'repo_type': 'files', 'path': '../Data/Sample/request'},\n",
                "            }],\n",
                "\n",
                "            # Perform Analytics to link entities in Requests and Content nodes\n",
                "            [ \"../Stage_3_Connect/Entity_Cosin_Similarity.ipynb\",{\n",
                "                \"sentence_embedding_model\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
                "                \"connect_threshold\": 0.6,\n",
                "                \"hypothesize_threshold\": 0.9\n",
                "            }],\n",
                "\n",
                "            # Compute recommendations based on relevance of content to request\n",
                "            [ \"../Stage_4_Recommend/Shortest_Path_Scoring.ipynb\", {\n",
                "                \"recommendation_threshold\": 0.6\n",
                "            }],\n",
                "\n",
                "            # Generate a summary of the content that is tailored with respect to the request and useful reference knowledge\n",
                "            [ \"../Stage_5_Summarize/Tailored_Abstractive_Summary.ipynb\", {\n",
                "                \"llm_model_path\": \"../LLM_Models/mistral-7b-openorca.gguf2.Q4_0.gguf\",\n",
                "                \"llm_prompt\": \"You are a helpful assistant responding to the request: {request} \\n\\n and were given these facts: {knowledge} \\n\\n Concisely summarize the following article: {content}\"\n",
                "            }],\n",
                "\n",
                "            # Produce a TLDR Report for each request\n",
                "            [ \"../Stage_6_Produce/Build_TLDR.ipynb\", {}],\n",
                "\n",
                "            # Run the Evaluation\n",
                "            [ \"../Stage_7_Evaluate/Evaluate.ipynb\", {\n",
                "                \"data_repo_config\": {'repo_type': 'files', 'path': '../Data/Sample/evalkey'},\n",
                "                \"sentence_embedding_model\": \"sentence-transformers/all-MiniLM-L6-v2\"\n",
                "            }]\n",
                "        ]}\n",
                "\n",
                "\n",
                "    wf:Workflow = Workflow(workflow)\n",
                "    wf.run()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "workflow = {\n",
                "    \"Output\": \"./READ_ONLY_OUTPUT/PREP\",\n",
                "    \"Notebooks\": [\n",
                "        [\"Step_1_Ingest.ipynb\", {\n",
                "            \"active_data_repo_config\": {'repo_type': 'files', 'path': \"./arxiv/content/\"},\n",
                "            }],\n",
                "        [\"Step_2_Connect.ipynb\",{\n",
                "            \"sentence_embedding_model\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
                "            \"threshold_similarity_connect\": 0.6,\n",
                "            \"threshold_similarity_hypothesize\": 0.9\n",
                "            }],\n",
                "        \n",
                "    ]}\n",
                "wf:Workflow = Workflow(workflow)\n",
                "wf.run()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "opentldr-env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}